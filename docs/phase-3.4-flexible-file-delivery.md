# Phase 3.4: Flexible File Delivery

## Overview

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–æ—Å—Ç–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ —Å –¥–≤—É–º—è –∫–ª—é—á–µ–≤—ã–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏:
1. **preview_file** - –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ (CSV, XLSX, PDF, text) –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
2. **sequential delivery** - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏

## Problem Statement

### –¢–µ–∫—É—â–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:

1. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞**: –ö–æ–≥–¥–∞ Claude –≤—ã–∑—ã–≤–∞–µ—Ç `deliver_file` –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ –æ–¥–Ω–æ–º turn, –≤—Å–µ —Ñ–∞–π–ª—ã –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –Ω–∏–º–∏.

2. **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π preview**: Claude –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–æ–≤:
   - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ‚úÖ –ø–æ–ª–Ω—ã–π base64 preview
   - CSV: ‚ö†Ô∏è —Ç–æ–ª—å–∫–æ header + —Ä–∞–∑–º–µ—Ä
   - XLSX: ‚ùå —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
   - PDF: ‚ùå —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü

### –ñ–µ–ª–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:

```
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: "–û–±—ä—è—Å–Ω–∏ –¥–≤–∞ –º–µ—Ç–æ–¥–∞ —Ä–µ—à–µ–Ω–∏—è –î–£ —Å —Ñ–æ—Ä–º—É–ª–∞–º–∏"

Claude: "–ú–µ—Ç–æ–¥ –≠–π–ª–µ—Ä–∞ - –ø—Ä–æ—Å—Ç–µ–π—à–∏–π —á–∏—Å–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥..."
[render_latex ‚Üí preview ‚Üí deliver_file(sequential=True)]
‚Üí –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ä–º—É–ª–∞ –≠–π–ª–µ—Ä–∞

Claude: "–ú–µ—Ç–æ–¥ –†—É–Ω–≥–µ-–ö—É—Ç—Ç—ã –±–æ–ª–µ–µ —Ç–æ—á–µ–Ω..."
[render_latex ‚Üí preview ‚Üí deliver_file(sequential=True)]
‚Üí –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ä–º—É–ª–∞ –†—É–Ω–≥–µ-–ö—É—Ç—Ç—ã

Claude: "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤..."
```

---

## Architecture

### –ù–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

```
bot/core/tools/
‚îú‚îÄ‚îÄ preview_file.py      # NEW: –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏
‚îú‚îÄ‚îÄ deliver_file.py      # MODIFIED: + sequential parameter
‚îî‚îÄ‚îÄ registry.py          # MODIFIED: + preview_file

bot/telegram/handlers/
‚îú‚îÄ‚îÄ claude.py            # MODIFIED: handle _force_turn_break
‚îî‚îÄ‚îÄ claude_tools.py      # MODIFIED: sequential delivery logic
```

### Flow diagram:

```
execute_python/render_latex
        ‚îÇ
        ‚ñº
   output_files: [{temp_id, preview}]
        ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                                 ‚ñº
  preview_file(temp_id)           deliver_file(temp_id)
  [–î–ª—è CSV/XLSX/PDF –∞–Ω–∞–ª–∏–∑–∞]      [–û–±—ã—á–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞]
        ‚îÇ                                 ‚îÇ
        ‚ñº                                 ‚ñº
  –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Ñ–∞–π–ª–∞            –§–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω
  (–ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–æ–∫, etc)           –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        ‚îÇ
        ‚ñº
  Claude –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç
        ‚îÇ
        ‚ñº
  deliver_file(temp_id, sequential=True)
        ‚îÇ
        ‚ñº
  –§–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω + TURN BREAK
        ‚îÇ
        ‚ñº
  Claude –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –≤ –Ω–æ–≤–æ–º turn
```

---

## Implementation Plan

### Stage 1: preview_file tool

**–¶–µ–ª—å**: Claude –º–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.

#### 1.1 –°–æ–∑–¥–∞—Ç—å `bot/core/tools/preview_file.py`

```python
"""Preview cached file content without delivering to user.

Allows Claude to analyze file content (CSV rows, text content, etc.)
before deciding whether to deliver or regenerate.
"""

from typing import Any, Dict, TYPE_CHECKING
from cache.exec_cache import get_exec_file, get_exec_meta
from utils.structured_logging import get_logger

if TYPE_CHECKING:
    from aiogram import Bot
    from sqlalchemy.ext.asyncio import AsyncSession

logger = get_logger(__name__)

PREVIEW_FILE_TOOL = {
    "name": "preview_file",
    "description": """Preview cached file content without sending to user.

<purpose>
Analyze file content before deciding to deliver. Useful for:
- CSV/XLSX: See actual data rows, verify column values
- Text files: Read full content
- PDF: Cannot preview content (use deliver_file then analyze_pdf)
- Images: Already visible in execute_python/render_latex result
</purpose>

<when_to_use>
- Verify CSV data is correct before sending
- Check text file content matches expectations
- Analyze tabular data quality
</when_to_use>

<parameters>
- temp_id: From output_files (e.g., "exec_abc123")
- max_rows: For CSV/XLSX, limit rows returned (default: 20)
- max_chars: For text files, limit characters (default: 5000)
</parameters>

<workflow>
1. execute_python generates CSV ‚Üí output_files with temp_id
2. preview_file(temp_id, max_rows=10) ‚Üí see first 10 rows
3. If data looks good ‚Üí deliver_file(temp_id)
4. If data wrong ‚Üí re-run execute_python with fixes
</workflow>""",
    "input_schema": {
        "type": "object",
        "properties": {
            "temp_id": {
                "type": "string",
                "description": "Temporary file ID from output_files"
            },
            "max_rows": {
                "type": "integer",
                "description": "Max rows for CSV/XLSX (default: 20)"
            },
            "max_chars": {
                "type": "integer",
                "description": "Max characters for text files (default: 5000)"
            }
        },
        "required": ["temp_id"]
    }
}


async def preview_file(
    temp_id: str,
    bot: 'Bot',
    session: 'AsyncSession',
    max_rows: int = 20,
    max_chars: int = 5000,
) -> Dict[str, Any]:
    """Preview file content from cache.

    Args:
        temp_id: Temporary file ID.
        bot: Bot instance (unused, interface consistency).
        session: DB session (unused, interface consistency).
        max_rows: Maximum rows for tabular data.
        max_chars: Maximum characters for text.

    Returns:
        Dict with file content or error.
    """
    _ = bot, session  # Unused

    logger.info("tools.preview_file.called", temp_id=temp_id)

    # Get metadata
    metadata = await get_exec_meta(temp_id)
    if not metadata:
        return {
            "success": "false",
            "error": f"File '{temp_id}' not found or expired (30 min TTL)"
        }

    # Get content
    content = await get_exec_file(temp_id)
    if not content:
        return {
            "success": "false",
            "error": f"File content for '{temp_id}' not found"
        }

    mime_type = metadata.get("mime_type", "")
    filename = metadata.get("filename", "")

    # Handle different file types
    if mime_type == "text/csv" or filename.endswith(".csv"):
        return _preview_csv(content, metadata, max_rows)

    elif mime_type in (
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "application/vnd.ms-excel"
    ) or filename.endswith((".xlsx", ".xls")):
        return _preview_excel(content, metadata, max_rows)

    elif mime_type.startswith("text/") or mime_type in (
        "application/json", "application/xml", "application/javascript"
    ):
        return _preview_text(content, metadata, max_chars)

    elif mime_type.startswith("image/"):
        return {
            "success": "true",
            "message": "Image files are already visible in tool results. "
                       "No separate preview needed.",
            "filename": filename,
            "size_bytes": len(content),
        }

    elif mime_type == "application/pdf":
        return {
            "success": "true",
            "message": "PDF content cannot be previewed directly. "
                       "Use deliver_file first, then analyze_pdf with "
                       "the returned claude_file_id.",
            "filename": filename,
            "size_bytes": len(content),
            "preview": metadata.get("preview", ""),
        }

    else:
        return {
            "success": "true",
            "message": f"Binary file type '{mime_type}' cannot be previewed. "
                       "Use deliver_file to send to user.",
            "filename": filename,
            "size_bytes": len(content),
        }


def _preview_csv(
    content: bytes,
    metadata: dict,
    max_rows: int
) -> Dict[str, Any]:
    """Preview CSV file content."""
    try:
        import io
        import csv

        text = content.decode("utf-8")
        reader = csv.reader(io.StringIO(text))

        rows = []
        for i, row in enumerate(reader):
            if i >= max_rows + 1:  # +1 for header
                break
            rows.append(row)

        if not rows:
            return {"success": "false", "error": "Empty CSV file"}

        header = rows[0]
        data_rows = rows[1:]
        total_rows = text.count('\n')

        # Format as table
        table_str = " | ".join(header) + "\n"
        table_str += "-" * len(table_str) + "\n"
        for row in data_rows:
            table_str += " | ".join(str(cell)[:50] for cell in row) + "\n"

        return {
            "success": "true",
            "filename": metadata.get("filename"),
            "columns": header,
            "column_count": len(header),
            "total_rows": total_rows,
            "previewed_rows": len(data_rows),
            "data_preview": table_str,
            "message": f"Showing {len(data_rows)} of ~{total_rows} rows"
        }

    except Exception as e:
        return {"success": "false", "error": f"CSV parse error: {str(e)}"}


def _preview_excel(
    content: bytes,
    metadata: dict,
    max_rows: int
) -> Dict[str, Any]:
    """Preview Excel file content."""
    try:
        import io
        import openpyxl

        wb = openpyxl.load_workbook(io.BytesIO(content), read_only=True)
        sheet = wb.active

        rows = []
        for i, row in enumerate(sheet.iter_rows(values_only=True)):
            if i >= max_rows + 1:
                break
            rows.append([str(cell) if cell is not None else "" for cell in row])

        if not rows:
            return {"success": "false", "error": "Empty Excel file"}

        header = rows[0]
        data_rows = rows[1:]

        # Format as table
        table_str = " | ".join(header) + "\n"
        table_str += "-" * len(table_str) + "\n"
        for row in data_rows:
            table_str += " | ".join(str(cell)[:50] for cell in row) + "\n"

        return {
            "success": "true",
            "filename": metadata.get("filename"),
            "sheet_name": sheet.title,
            "columns": header,
            "column_count": len(header),
            "total_rows": sheet.max_row,
            "previewed_rows": len(data_rows),
            "data_preview": table_str,
            "message": f"Showing {len(data_rows)} of {sheet.max_row} rows"
        }

    except Exception as e:
        return {"success": "false", "error": f"Excel parse error: {str(e)}"}


def _preview_text(
    content: bytes,
    metadata: dict,
    max_chars: int
) -> Dict[str, Any]:
    """Preview text file content."""
    try:
        text = content.decode("utf-8")
        truncated = len(text) > max_chars
        preview = text[:max_chars]

        return {
            "success": "true",
            "filename": metadata.get("filename"),
            "total_chars": len(text),
            "total_lines": text.count('\n') + 1,
            "content": preview,
            "truncated": truncated,
            "message": f"Showing {len(preview)} of {len(text)} characters"
                       if truncated else "Full content shown"
        }

    except Exception as e:
        return {"success": "false", "error": f"Text decode error: {str(e)}"}


def format_preview_file_result(
    tool_input: Dict[str, Any],
    result: Dict[str, Any],
) -> str:
    """Format preview_file result for user display."""
    if result.get("success") == "true":
        filename = result.get("filename", "file")
        if "data_preview" in result:
            rows = result.get("previewed_rows", 0)
            return f"[üìã Previewed {filename}: {rows} rows]"
        elif "content" in result:
            chars = len(result.get("content", ""))
            return f"[üìÑ Previewed {filename}: {chars} chars]"
        return f"[üìÅ {result.get('message', 'File info retrieved')}]"

    error = result.get("error", "unknown")
    return f"[‚ùå Preview failed: {error[:60]}]"


# Tool configuration
from core.tools.base import ToolConfig

TOOL_CONFIG = ToolConfig(
    name="preview_file",
    definition=PREVIEW_FILE_TOOL,
    executor=preview_file,
    emoji="üëÅÔ∏è",
    needs_bot_session=True,
    format_result=format_preview_file_result,
)
```

#### 1.2 –î–æ–±–∞–≤–∏—Ç—å –≤ registry.py

```python
from core.tools.preview_file import TOOL_CONFIG as PREVIEW_FILE_CONFIG

TOOLS: Dict[str, ToolConfig] = {
    # ... existing tools ...
    "preview_file": PREVIEW_FILE_CONFIG,
}
```

#### 1.3 –î–æ–±–∞–≤–∏—Ç—å openpyxl –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```toml
# pyproject.toml
dependencies = [
    # ... existing ...
    "openpyxl>=3.1.0",  # Excel file reading
]
```

---

### Stage 2: Sequential delivery

**–¶–µ–ª—å**: `deliver_file(sequential=True)` —Ñ–æ—Ä—Å–∏—Ä—É–µ—Ç turn break –ø–æ—Å–ª–µ –¥–æ—Å—Ç–∞–≤–∫–∏.

#### 2.1 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å `deliver_file.py`

```python
DELIVER_FILE_TOOL = {
    "name": "deliver_file",
    "description": """Deliver a cached file to the user.

<purpose>
Send files generated by execute_python/render_latex to user.
Files are cached for 30 min until delivered.
</purpose>

<delivery_modes>
DEFAULT (sequential=false):
  Multiple deliver_file calls send files in parallel.
  Use when files are related and should appear together.
  Example: "Here are both charts" ‚Üí deliver_file √ó 2

SEQUENTIAL (sequential=true):
  Forces a turn break after delivery. Claude continues
  in next turn, allowing text between files.
  Use when explaining files one by one.
  Example: "First method..." ‚Üí deliver ‚Üí "Second method..." ‚Üí deliver
</delivery_modes>

<workflow>
1. execute_python/render_latex ‚Üí output_files with temp_id
2. (Optional) preview_file(temp_id) to verify content
3. deliver_file(temp_id) or deliver_file(temp_id, sequential=true)
</workflow>""",
    "input_schema": {
        "type": "object",
        "properties": {
            "temp_id": {
                "type": "string",
                "description": "Temporary file ID from output_files"
            },
            "caption": {
                "type": "string",
                "description": "Optional brief caption for the file"
            },
            "sequential": {
                "type": "boolean",
                "description": "If true, forces turn break after delivery. "
                               "Use when you need to write text after this "
                               "file before delivering next file. Default: false"
            }
        },
        "required": ["temp_id"]
    },
}


async def deliver_file(
    temp_id: str,
    bot: 'Bot',
    session: 'AsyncSession',
    caption: str | None = None,
    sequential: bool = False,
) -> Dict[str, Any]:
    """Deliver cached file to user.

    Args:
        temp_id: Temporary file ID.
        bot: Bot instance.
        session: DB session.
        caption: Optional caption.
        sequential: If True, force turn break after delivery.

    Returns:
        Result dict with _file_contents and optional _force_turn_break.
    """
    # ... existing implementation ...

    result: Dict[str, Any] = {
        "success": "true",
        "_file_contents": [{
            "filename": filename,
            "content": content,
            "mime_type": mime_type,
        }],
    }

    if caption:
        result["caption"] = caption

    # NEW: Sequential delivery marker
    if sequential:
        result["_force_turn_break"] = True
        logger.info("tools.deliver_file.sequential_mode",
                    temp_id=temp_id,
                    filename=filename)

    return result
```

#### 2.2 –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å tool loop –≤ `claude.py`

–í —Ñ—É–Ω–∫—Ü–∏–∏ `_stream_with_unified_events`, –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ tool results:

```python
# After processing all tools in parallel
for coro in asyncio.as_completed(tool_tasks):
    idx, result = await coro
    tool = pending_tools[idx]

    # ... existing file processing ...

    # Check for sequential delivery
    if result.get("_force_turn_break"):
        # Mark that we need to break after this iteration
        force_turn_break = True
        # Store which tool triggered it for logging
        turn_break_tool = tool.name

    results[idx] = clean_result

# After formatting tool results and adding to conversation
if force_turn_break:
    logger.info("stream.unified.forced_turn_break",
                thread_id=thread_id,
                triggered_by=turn_break_tool)

    # Don't continue tool loop - return control to Claude
    # Claude will continue in a new API call with updated context

    # Get current text as partial answer
    partial_answer = stream.get_final_text()
    partial_display = stream.get_final_display()

    # Finalize current draft
    final_message = None
    if partial_display.strip():
        try:
            final_message = await dm.current.finalize(
                final_text=partial_display)
        except Exception as e:
            logger.error("stream.draft_finalize_failed",
                         thread_id=thread_id,
                         error=str(e))

    # Return with marker for handler to continue
    return partial_answer, final_message, True  # True = needs_continuation

# Normal end of iteration
return final_answer, final_message, False
```

#### 2.3 –û–±—Ä–∞–±–æ—Ç–∫–∞ continuation –≤ `_process_message_batch`

```python
async def _process_message_batch(...):
    # ... existing setup ...

    max_continuations = 5  # Prevent infinite loops

    for continuation in range(max_continuations):
        response_text, bot_message, needs_continuation = \
            await _stream_with_unified_events(...)

        if not needs_continuation:
            break

        logger.info("claude_handler.continuation_needed",
                    thread_id=thread_id,
                    continuation=continuation + 1)

        # Save partial response to DB
        # ... save message ...

        # Continue with new request (context includes tool results)
        # Request is rebuilt with updated conversation history

    else:
        logger.warning("claude_handler.max_continuations",
                       thread_id=thread_id)
```

---

### Stage 3: System prompt updates

#### 3.1 –û–±–Ω–æ–≤–∏—Ç—å `GLOBAL_SYSTEM_PROMPT` –≤ `config.py`

–î–æ–±–∞–≤–∏—Ç—å —Å–µ–∫—Ü–∏—é –æ file delivery:

```python
FILE_DELIVERY_GUIDELINES = """
## File Delivery Guidelines

When generating files (via execute_python, render_latex):

### Verify Before Delivery
- Images: Already visible in tool results - check quality visually
- CSV/XLSX: Use preview_file to verify data before sending
- PDF: Check preview metadata (pages, size), deliver then analyze_pdf if needed

### Delivery Modes

**Parallel delivery** (default):
When files are related and should appear together.
```
execute_python ‚Üí [chart1.png, chart2.png]
deliver_file(temp_id_1)
deliver_file(temp_id_2)
‚Üí Both charts sent together
```

**Sequential delivery** (sequential=true):
When explaining files one by one with text between them.
```
"–ú–µ—Ç–æ–¥ –≠–π–ª–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é..."
render_latex ‚Üí formula1
deliver_file(temp_id_1, sequential=true)
‚Üí Formula sent, turn break

"–ú–µ—Ç–æ–¥ –†—É–Ω–≥–µ-–ö—É—Ç—Ç—ã –±–æ–ª–µ–µ —Ç–æ—á–µ–Ω..."
render_latex ‚Üí formula2
deliver_file(temp_id_2, sequential=true)
‚Üí Formula sent
```

### Decision Guide
- User asks for "two charts comparing X and Y" ‚Üí parallel (related)
- User asks to "explain two methods with formulas" ‚Üí sequential (needs text between)
- User asks to "generate a report" ‚Üí single file, no sequential needed
- Uncertain? Default to parallel, it's faster
"""
```

---

### Stage 4: Tests

#### 4.1 `tests/core/tools/test_preview_file.py`

```python
"""Tests for preview_file tool."""

import pytest
from core.tools.preview_file import (
    preview_file,
    _preview_csv,
    _preview_excel,
    _preview_text,
)


class TestPreviewCSV:
    """Tests for CSV preview."""

    def test_preview_csv_basic(self):
        content = b"name,age,city\nAlice,30,NYC\nBob,25,LA"
        metadata = {"filename": "data.csv"}

        result = _preview_csv(content, metadata, max_rows=10)

        assert result["success"] == "true"
        assert result["columns"] == ["name", "age", "city"]
        assert result["column_count"] == 3
        assert result["previewed_rows"] == 2
        assert "Alice" in result["data_preview"]

    def test_preview_csv_truncation(self):
        rows = ["col1,col2"] + [f"row{i},val{i}" for i in range(100)]
        content = "\n".join(rows).encode()
        metadata = {"filename": "big.csv"}

        result = _preview_csv(content, metadata, max_rows=5)

        assert result["previewed_rows"] == 5
        assert result["total_rows"] == 101

    def test_preview_csv_empty(self):
        result = _preview_csv(b"", {"filename": "empty.csv"}, 10)
        assert result["success"] == "false"


class TestPreviewText:
    """Tests for text preview."""

    def test_preview_text_full(self):
        content = b"Hello world\nLine 2\nLine 3"
        metadata = {"filename": "test.txt"}

        result = _preview_text(content, metadata, max_chars=1000)

        assert result["success"] == "true"
        assert result["content"] == "Hello world\nLine 2\nLine 3"
        assert result["truncated"] is False

    def test_preview_text_truncated(self):
        content = b"x" * 1000
        metadata = {"filename": "long.txt"}

        result = _preview_text(content, metadata, max_chars=100)

        assert len(result["content"]) == 100
        assert result["truncated"] is True


class TestDeliverFileSequential:
    """Tests for sequential delivery mode."""

    @pytest.mark.asyncio
    async def test_sequential_flag_in_result(self, mock_cache):
        """Sequential=True adds _force_turn_break marker."""
        mock_cache.set_file("exec_abc", b"content", {
            "filename": "test.png",
            "mime_type": "image/png"
        })

        from core.tools.deliver_file import deliver_file

        result = await deliver_file(
            temp_id="exec_abc",
            bot=None,
            session=None,
            sequential=True
        )

        assert result["_force_turn_break"] is True

    @pytest.mark.asyncio
    async def test_default_no_turn_break(self, mock_cache):
        """Default mode has no _force_turn_break."""
        mock_cache.set_file("exec_abc", b"content", {
            "filename": "test.png",
            "mime_type": "image/png"
        })

        from core.tools.deliver_file import deliver_file

        result = await deliver_file(
            temp_id="exec_abc",
            bot=None,
            session=None,
            sequential=False
        )

        assert "_force_turn_break" not in result
```

---

## File Changes Summary

### New Files:
- `bot/core/tools/preview_file.py` - Preview tool implementation
- `bot/tests/core/tools/test_preview_file.py` - Preview tool tests

### Modified Files:
- `bot/core/tools/deliver_file.py` - Add sequential parameter
- `bot/core/tools/registry.py` - Register preview_file
- `bot/telegram/handlers/claude.py` - Handle _force_turn_break
- `bot/config.py` - Update system prompt
- `bot/pyproject.toml` - Add openpyxl dependency
- `bot/Dockerfile` - Ensure openpyxl installed

---

## Migration

No database changes required. Redis cache format unchanged.

## Rollback

Remove `sequential` parameter handling - deliver_file falls back to parallel mode.

---

## Cost Impact

- **preview_file**: No API cost (local processing)
- **sequential=true**: +1 Claude API call per sequential delivery
  - Typical: 2 sequential files = 2 extra turns = ~2x token cost for that interaction
  - Mitigated by: prompt caching, user pays per token anyway

## Performance Impact

- **preview_file**: <10ms for CSV/text, <100ms for XLSX
- **sequential delivery**: +latency for each turn break (~1-3s per file)

---

## Future Enhancements

1. **Inline markers** (V4): Parse `[DELIVER:temp_id]` from text for true mixed content
2. **Batch preview**: `preview_files([temp_id1, temp_id2])` for efficiency
3. **Smart auto-sequential**: Detect when Claude writes text between deliver calls
