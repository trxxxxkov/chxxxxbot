"""Deliver cached execution file to user.

This module implements the deliver_file tool for sending files
generated by execute_python/render_latex from Redis cache to the user.

Phase 3.2+: Files generated by execute_python are cached in Redis.
The model decides whether to deliver files based on user request
and file quality. This tool retrieves cached files and delivers them.

Phase 3.4: Added sequential delivery mode for turn breaks between files.

NO __init__.py - use direct import:
    from core.tools.deliver_file import deliver_file, DELIVER_FILE_TOOL
"""

from typing import Any, Dict, TYPE_CHECKING

from cache.exec_cache import delete_exec_file
from cache.exec_cache import get_exec_file
from cache.exec_cache import get_exec_meta
from utils.structured_logging import get_logger

if TYPE_CHECKING:
    from aiogram import Bot
    from sqlalchemy.ext.asyncio import AsyncSession

logger = get_logger(__name__)

# Tool definition for Claude API
DELIVER_FILE_TOOL = {
    "name":
        "deliver_file",
    "description":
        """Deliver a cached file to the user.

<purpose>
Send files generated by execute_python/render_latex to the user.
Files are cached in Redis (30 min TTL) until you deliver them.
</purpose>

<delivery_modes>
**DEFAULT (sequential=false):**
Multiple deliver_file calls in same turn send files in parallel.
Use when files are related and should appear together.
Example: "Here are both charts" â†’ deliver_file Ã— 2 â†’ both sent together

**SEQUENTIAL (sequential=true):**
Forces a turn break after delivery. You continue in next turn,
allowing text BETWEEN files.
Example:
  "ÐœÐµÑ‚Ð¾Ð´ Ð­Ð¹Ð»ÐµÑ€Ð°..." â†’ deliver_file(sequential=true) â†’ file sent
  [new turn] "ÐœÐµÑ‚Ð¾Ð´ Ð ÑƒÐ½Ð³Ðµ-ÐšÑƒÑ‚Ñ‚Ñ‹..." â†’ deliver_file(sequential=true)
</delivery_modes>

<when_to_use_sequential>
Use sequential=true when:
- Explaining multiple files one by one with text between
- User asked to "explain each method" or "show step by step"
- Each file needs its own context/description

Use default (parallel) when:
- Files are related ("both charts", "before and after")
- Single delivery with no text between needed
- Speed matters more than ordering
</when_to_use_sequential>

<workflow>
1. execute_python/render_latex â†’ output_files with temp_id
2. (Optional) preview_file(temp_id) for CSV/XLSX verification
3. deliver_file(temp_id) or deliver_file(temp_id, sequential=true)
</workflow>

<cache_expiry>
Files expire after 30 minutes. If temp_id not found:
- Inform user that file expired
- Regenerate with execute_python/render_latex if needed
</cache_expiry>""",
    "input_schema": {
        "type": "object",
        "properties": {
            "temp_id": {
                "type": "string",
                "description": "Temporary file ID from output_files "
                               "(e.g., 'exec_abc123' or 'render_def456')"
            },
            "caption": {
                "type": "string",
                "description": "Optional brief caption (1-2 sentences)"
            },
            "sequential": {
                "type": "boolean",
                "description":
                    "If true, forces turn break after delivery. "
                    "Use when you need to write text after this file "
                    "before delivering the next one. Default: false"
            }
        },
        "required": ["temp_id"]
    },
}


async def deliver_file(
    temp_id: str,
    bot: 'Bot',  # pylint: disable=unused-argument
    session: 'AsyncSession',  # pylint: disable=unused-argument
    thread_id: int | None = None,  # pylint: disable=unused-argument
    caption: str | None = None,
    sequential: bool = False,
) -> Dict[str, Any]:
    """Deliver cached execution file to user.

    Retrieves file from Redis cache and prepares it for delivery
    via the _file_contents pattern (handled by claude handler).

    Args:
        temp_id: Temporary file ID from execute_python/render_latex.
        bot: Telegram Bot instance (unused, for interface consistency).
        session: Database session (unused, for interface consistency).
        caption: Optional caption for the file.
        sequential: If True, handler will force turn break after delivery.
            This allows Claude to write text between file deliveries.

    Returns:
        Dictionary with delivery result:
        - On success: {"success": "true", "_file_contents": [...],
                       "_force_turn_break": True (if sequential)}
        - On failure: {"success": "false", "error": "..."}

    Examples:
        >>> # Parallel delivery (default)
        >>> result = await deliver_file(temp_id="exec_abc123", ...)

        >>> # Sequential delivery with turn break
        >>> result = await deliver_file(
        ...     temp_id="exec_abc123",
        ...     sequential=True,
        ...     ...
        ... )
        >>> result["_force_turn_break"]
        True
    """
    logger.info("tools.deliver_file.called",
                temp_id=temp_id,
                has_caption=bool(caption),
                sequential=sequential)

    try:
        # Step 1: Get metadata from cache
        metadata = await get_exec_meta(temp_id)
        if metadata is None:
            logger.warning("tools.deliver_file.meta_not_found", temp_id=temp_id)
            return {
                "success":
                    "false",
                "error": (f"File '{temp_id}' not found in cache. "
                          "It may have expired (30 min TTL). "
                          "Use execute_python/render_latex to regenerate."),
            }

        # Step 2: Get file content from cache
        content = await get_exec_file(temp_id)
        if content is None:
            logger.warning("tools.deliver_file.content_not_found",
                           temp_id=temp_id)
            return {
                "success":
                    "false",
                "error": (f"File content for '{temp_id}' not found. "
                          "It may have expired (30 min TTL). "
                          "Use execute_python/render_latex to regenerate."),
            }

        filename = metadata["filename"]
        mime_type = metadata["mime_type"]
        # Use context from metadata (set by tool that created the file)
        file_context = metadata.get("context")
        size_bytes = len(content)

        logger.info("tools.deliver_file.file_retrieved",
                    temp_id=temp_id,
                    filename=filename,
                    mime_type=mime_type,
                    size_bytes=size_bytes)

        # Step 3: Delete from cache (file will be in Files API after delivery)
        # This prevents duplicate delivery and frees cache space
        deleted = await delete_exec_file(temp_id)
        if deleted:
            logger.debug("tools.deliver_file.cache_cleaned", temp_id=temp_id)

        # Step 4: Return with _file_contents for handler processing
        # Handler will: upload to Files API, send to Telegram, save to DB
        result: Dict[str, Any] = {
            "success":
                "true",
            "_file_contents": [{
                "filename": filename,
                "content": content,
                "mime_type": mime_type,
                "context": file_context,
            }],
        }

        # Include caption in result for potential use in response
        if caption:
            result["caption"] = caption

        # Phase 3.4: Sequential delivery mode
        # When sequential=True, handler will force a turn break after delivery
        # This allows Claude to write text between file deliveries
        if sequential:
            result["_force_turn_break"] = True
            logger.info("tools.deliver_file.sequential_mode",
                        temp_id=temp_id,
                        filename=filename)

        logger.info("tools.deliver_file.success",
                    temp_id=temp_id,
                    filename=filename,
                    size_bytes=size_bytes,
                    sequential=sequential)

        return result

    except Exception as e:
        logger.error("tools.deliver_file.failed",
                     temp_id=temp_id,
                     error=str(e),
                     exc_info=True)
        return {
            "success": "false",
            "error": f"Failed to deliver file: {str(e)}",
        }


def format_deliver_file_result(
    tool_input: Dict[str, Any],
    result: Dict[str, Any],
) -> str:
    """Format deliver_file result for user display.

    Args:
        tool_input: The input parameters (temp_id, caption, sequential).
        result: The result dictionary with success, error.

    Returns:
        Formatted system message string.
    """
    _ = tool_input  # Unused
    if result.get("success") == "true":
        # File delivered - message comes from files_delivered in handler
        return ""  # No extra message needed, file speaks for itself

    error = result.get("error", "unknown error")
    preview = error[:80] + "..." if len(error) > 80 else error
    return f"[Failed to deliver file: {preview}]"


# Unified tool configuration
from core.tools.base import ToolConfig  # pylint: disable=wrong-import-position

TOOL_CONFIG = ToolConfig(
    name="deliver_file",
    definition=DELIVER_FILE_TOOL,
    executor=deliver_file,
    emoji="ðŸ“¤",
    needs_bot_session=True,
    format_result=format_deliver_file_result,
)
