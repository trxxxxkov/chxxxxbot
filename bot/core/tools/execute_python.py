"""Execute Python code tool using E2B Code Interpreter.

This module implements the execute_python tool for running AI-generated
Python code in secure sandboxed environments with internet access and
pip package installation support.

NO __init__.py - use direct import:
    from core.tools.execute_python import execute_python, EXECUTE_PYTHON_TOOL
"""

import asyncio
import json
from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING

from core.clients import get_e2b_api_key
from core.mime_types import detect_mime_type
from core.pricing import calculate_e2b_cost
from core.pricing import cost_to_float
from e2b_code_interpreter import Sandbox
from utils.structured_logging import get_logger

if TYPE_CHECKING:
    from aiogram import Bot
    from sqlalchemy.ext.asyncio import AsyncSession

logger = get_logger(__name__)


async def download_user_file(file_id: str, filename: str, bot: 'Bot',
                             session: 'AsyncSession') -> bytes:
    """Download user file from Telegram or Files API.

    User files (uploaded by user): Download from Telegram storage.
    Bot files (generated by execute_python): Download from Files API.

    Args:
        file_id: Claude file_id (used to lookup in database).
        filename: Original filename for logging.
        bot: Telegram Bot instance for downloading files.
        session: Database session for querying file metadata.

    Returns:
        File content as bytes.

    Raises:
        ValueError: If file not found or no longer available.
        TelegramAPIError: If Telegram download fails.
        anthropic.APIError: If Files API download fails.

    Note:
        Telegram stores files for ~6 months of inactivity.
        Files API stores files for 24 hours (configurable).
    """
    # Import here to avoid circular dependencies
    from aiogram.exceptions import \
        TelegramAPIError  # pylint: disable=import-outside-toplevel
    from db.models.user_file import \
        FileSource  # pylint: disable=import-outside-toplevel
    from db.repositories.user_file_repository import \
        UserFileRepository  # pylint: disable=import-outside-toplevel

    logger.info("tools.execute_python.downloading_user_file",
                file_id=file_id,
                filename=filename)

    # Get file metadata from database
    repo = UserFileRepository(session)
    file_record = await repo.get_by_claude_file_id(file_id)

    if not file_record:
        raise ValueError(f"File not found in database: {file_id}")

    # All files (both USER and ASSISTANT) should have telegram_file_id
    # and should be downloaded from Telegram
    if not file_record.telegram_file_id:
        raise ValueError(
            f"No telegram_file_id for file {file_id} ({filename}). "
            "Cannot download from Telegram. File may be from an older "
            "version before telegram_file_id was saved for generated files.")

    try:
        logger.info("tools.execute_python.telegram_download",
                    telegram_file_id=file_record.telegram_file_id,
                    filename=filename,
                    source=file_record.source.value)

        # Get file info from Telegram
        file_info = await bot.get_file(file_record.telegram_file_id)

        # Download file content
        file_bytes_io = await bot.download_file(file_info.file_path)

        # Read BytesIO to bytes
        file_bytes = file_bytes_io.read()

        logger.info("tools.execute_python.telegram_download_success",
                    file_id=file_id,
                    filename=filename,
                    size_bytes=len(file_bytes))

        return file_bytes

    except TelegramAPIError as e:
        logger.error("tools.execute_python.telegram_download_failed",
                     file_id=file_id,
                     telegram_file_id=file_record.telegram_file_id,
                     filename=filename,
                     error=str(e),
                     exc_info=True)

        # User-friendly error message
        raise ValueError(
            f"File '{filename}' is no longer available in Telegram. "
            "Files are stored for approximately 6 months. "
            "Please re-upload the file to continue.") from e


def _run_sandbox_sync(  # pylint: disable=too-many-locals,too-many-statements
    code: str,
    downloaded_files: Dict[str, bytes],
    requirements: Optional[str],
    timeout: float,
) -> Tuple[Dict[str, Any], float]:
    """Run code in E2B sandbox synchronously.

    This function is designed to be called via asyncio.to_thread() to avoid
    blocking the event loop during sandbox operations.

    Args:
        code: Python code to execute.
        downloaded_files: Pre-downloaded files as {filename: bytes}.
        requirements: Optional pip packages to install.
        timeout: Execution timeout in seconds.

    Returns:
        Tuple of (result_dict, sandbox_duration_seconds).
    """
    import os  # pylint: disable=import-outside-toplevel
    import time  # pylint: disable=import-outside-toplevel

    api_key = get_e2b_api_key()
    os.environ["E2B_API_KEY"] = api_key

    sandbox_start_time = time.time()

    with Sandbox.create() as sandbox:
        # Upload pre-downloaded files to sandbox
        if downloaded_files:
            sandbox.commands.run("mkdir -p /tmp/inputs")

            for filename, file_content in downloaded_files.items():
                sandbox_path = f"/tmp/inputs/{filename}"
                sandbox.files.write(sandbox_path, file_content)
                logger.info("tools.execute_python.file_uploaded_to_sandbox",
                            filename=filename,
                            sandbox_path=sandbox_path,
                            size_bytes=len(file_content))

        # Install pip packages if specified
        if requirements:
            logger.info("tools.execute_python.installing_packages",
                        requirements=requirements)
            install_output = sandbox.commands.run(f"pip install {requirements}")
            logger.info("tools.execute_python.packages_installed",
                        exit_code=install_output.exit_code,
                        stdout_length=len(install_output.stdout))

        # Execute code
        logger.info("tools.execute_python.executing_code",
                    code_length=len(code),
                    timeout=timeout)

        execution = sandbox.run_code(code=code, timeout=timeout)

        # Process execution results
        stdout_list = execution.logs.stdout if execution.logs else []
        stderr_list = execution.logs.stderr if execution.logs else []

        logger.info("tools.execute_python.execution_complete",
                    stdout_lines=len(stdout_list),
                    stderr_lines=len(stderr_list),
                    has_error=bool(execution.error),
                    has_results=bool(execution.results))

        stdout_str = "".join(stdout_list)
        stderr_str = "".join(stderr_list)
        error_str = str(execution.error) if execution.error else ""
        success = execution.error is None

        # Serialize results
        results_list = []
        if execution.results:
            for r in execution.results:
                logger.debug("tools.execute_python.result_object",
                             result_type=type(r).__name__,
                             result_str=str(r)[:200])
                results_list.append(str(r)[:1000])

        results_serialized = json.dumps(results_list, ensure_ascii=False)

        # Scan for generated files
        generated_files: List[Dict[str, Any]] = []

        try:
            logger.info("tools.execute_python.scanning_output_files")
            all_files = sandbox.files.list("/tmp")

            for entry in all_files:
                if not entry.name:
                    continue

                file_path = entry.path

                if file_path.startswith("/tmp/inputs/"):
                    continue

                if entry.name in ("inputs", ".ICE-unix", ".X11-unix"):
                    continue

                logger.info("tools.execute_python.downloading_output_file",
                            path=file_path,
                            name=entry.name)

                try:
                    file_bytes = sandbox.files.read(file_path, format="bytes")
                except Exception as read_error:  # pylint: disable=broad-exception-caught
                    logger.debug("tools.execute_python.skip_file",
                                 path=file_path,
                                 error=str(read_error))
                    continue

                # Detect MIME from magic bytes and extension (not just extension)
                mime_type = detect_mime_type(
                    filename=entry.name,
                    file_bytes=file_bytes,
                )

                generated_files.append({
                    "filename": entry.name,
                    "path": file_path,
                    "size": len(file_bytes),
                    "mime_type": mime_type,
                    "content": file_bytes
                })

                logger.info("tools.execute_python.output_file_found",
                            filename=entry.name,
                            size=len(file_bytes),
                            mime_type=mime_type)

            logger.info("tools.execute_python.output_files_scanned",
                        file_count=len(generated_files))

        except Exception as scan_error:  # pylint: disable=broad-exception-caught
            logger.warning("tools.execute_python.output_scan_failed",
                           error=str(scan_error),
                           exc_info=True)

        sandbox_end_time = time.time()
        sandbox_duration = sandbox_end_time - sandbox_start_time

        # Prepare result dict
        generated_files_meta = [{
            "filename": f["filename"],
            "path": f["path"],
            "size": f["size"],
            "mime_type": f["mime_type"]
        } for f in generated_files]

        result = {
            "stdout":
                stdout_str,
            "stderr":
                stderr_str,
            "results":
                results_serialized,
            "error":
                error_str,
            "success":
                str(success).lower(),
            "generated_files":
                json.dumps(generated_files_meta, ensure_ascii=False),
            "_file_contents":
                generated_files,
        }

        return result, sandbox_duration


# pylint: disable=too-many-locals,too-many-statements
async def execute_python(code: str,
                         bot: 'Bot',
                         session: 'AsyncSession',
                         file_inputs: Optional[List[Dict[str, str]]] = None,
                         requirements: Optional[str] = None,
                         timeout: Optional[float] = 3600.0) -> Dict[str, Any]:
    """Execute Python code in E2B sandbox with file support.

    Runs Python code in secure E2B sandbox (Linux, Python 3.11+, headless).
    Supports pip packages, internet access, input/output file operations.
    Sandboxes are ephemeral and destroyed after execution.

    Environment:
    - Working directory: /home/user
    - Input files (if file_inputs provided): /tmp/inputs/{filename}
    - Output files: Save to /tmp/ or subdirectories
    - Bot auto-detects and downloads all new files from /tmp/

    Args:
        code: Python code to execute. Can include imports, multiple
            lines, functions, classes, etc.
        bot: Telegram Bot instance for downloading user files.
        session: Database session for querying file metadata.
        file_inputs: Optional list of input files to upload to sandbox.
            Each item: {"file_id": "file_abc...", "name": "document.pdf"}.
            Files will be available at /tmp/inputs/{name}.
        requirements: Optional space-separated list of pip packages
            (e.g., "numpy pandas matplotlib requests").
        timeout: Maximum execution time in seconds. Default: 3600 seconds
            (1 hour). Can be reduced for faster feedback on simple tasks.

    Returns:
        Dictionary with execution results:
        - 'stdout': Standard output from the code.
        - 'stderr': Standard error output (warnings, errors).
        - 'results': Serialized results (matplotlib plots, return values).
        - 'error': Error message if execution failed, otherwise empty.
        - 'success': 'true' if no errors, 'false' otherwise.
        - 'generated_files': JSON list of generated files with metadata:
            [{"filename": "output.pdf", "size": 102400, "mime_type": "..."}]

    Raises:
        Exception: If sandbox creation, file operations, or execution fails.

    Examples:
        >>> # Simple execution
        >>> result = await execute_python(code="print('Hello!')")
        >>> print(result['stdout'])
        Hello!

        >>> # With input files
        >>> result = await execute_python(
        ...     code=("import pandas as pd; "
        ...           "df = pd.read_csv('/tmp/inputs/data.csv'); "
        ...           "print(df.head())"),
        ...     file_inputs=[{"file_id": "file_xyz", "name": "data.csv"}],
        ...     requirements="pandas"
        ... )

        >>> # With output files
        >>> result = await execute_python(
        ...     code="with open('/tmp/output.txt', 'w') as f: f.write('Result')"
        ... )
        >>> print(result['generated_files'])
        [{"filename": "output.txt", "size": 6, "mime_type": "text/plain"}]
    """
    try:
        logger.info("tools.execute_python.called",
                    code_length=len(code),
                    file_inputs_count=len(file_inputs or []),
                    requirements=requirements,
                    timeout=timeout)

        # Early validation: detect missing file_inputs when code expects files
        # This provides a clear error message instead of FileNotFoundError
        if '/tmp/inputs/' in code and not file_inputs:
            logger.warning("tools.execute_python.missing_file_inputs",
                           code_preview=code[:200])
            return {
                "stdout": "",
                "stderr": "",
                "results": "[]",
                "error": (
                    "Code references '/tmp/inputs/' but no file_inputs provided. "
                    "You must pass file_inputs parameter with file_id and name "
                    "from 'Available files' section to upload files to sandbox. "
                    "Example: file_inputs=[{\"file_id\": \"file_abc...\", "
                    "\"name\": \"data.csv\"}]"),
                "success": "false",
                "generated_files": "[]",
                "cost_usd": "0.000000",
            }

        # Step 1: Download all input files ASYNCHRONOUSLY before sandbox
        # This allows event loop to handle keepalive during downloads
        downloaded_files: Dict[str, bytes] = {}
        if file_inputs:
            logger.info("tools.execute_python.downloading_input_files",
                        file_count=len(file_inputs))

            for file_input in file_inputs:
                file_id = file_input["file_id"]
                filename = file_input["name"]

                logger.info("tools.execute_python.downloading_file_from_api",
                            file_id=file_id,
                            filename=filename)

                file_content = await download_user_file(file_id, filename, bot,
                                                        session)
                downloaded_files[filename] = file_content

                logger.info("tools.execute_python.file_downloaded",
                            file_id=file_id,
                            filename=filename,
                            size_bytes=len(file_content))

        # Step 2: Run sandbox in thread pool to avoid blocking event loop
        # This allows keepalive updates during long sandbox operations
        result, sandbox_duration = await asyncio.to_thread(
            _run_sandbox_sync,
            code,
            downloaded_files,
            requirements,
            timeout or 3600.0,
        )

        # Step 3: Add cost to result
        cost_usd = calculate_e2b_cost(sandbox_duration)
        result["cost_usd"] = f"{cost_to_float(cost_usd):.6f}"

        logger.info("tools.execute_python.success",
                    success=result["success"],
                    stdout_length=len(result["stdout"]),
                    stderr_length=len(result["stderr"]),
                    generated_files_count=len(result.get("_file_contents", [])),
                    has_error=bool(result["error"]),
                    sandbox_duration_seconds=round(sandbox_duration, 2),
                    cost_usd=cost_to_float(cost_usd))

        return result

    except Exception as e:
        logger.error("tools.execute_python.failed", error=str(e), exc_info=True)
        # Re-raise to let caller handle
        raise


# Tool definition for Claude API (anthropic tools format)
# Phase 1.5 Stage 6: Added cache_control for tool caching optimization
# This is the LAST tool in TOOL_DEFINITIONS, so cache_control here
# enables caching for ALL tool definitions (~3,268 tokens)
EXECUTE_PYTHON_TOOL = {
    "name":
        "execute_python",
    "description":
        """Execute Python code in secure E2B sandbox with file I/O support.

Use this when you need to: run code, perform calculations, analyze data,
make HTTP requests, process files, generate files (PDF/PNG/CSV/etc.),
or use Python libraries. Full internet + pip install support.

<environment>
E2B sandbox - Debian Linux, Python 3.11+, headless:
- Working directory: /home/user
- Input files (if file_inputs provided): /tmp/inputs/{filename}
- Output files: Save to /tmp/ or subdirectories (e.g., /tmp/output.pdf)
- Bot auto-downloads ALL new files from /tmp/ (excluding /tmp/inputs/)
- System: Full Debian with apt-get, subprocess for shell commands
- Pre-installed: Python standard library, pip, basic CLI tools
</environment>

<system_package_installation>
You can install ANY system packages via apt-get (sandbox is Debian-based).
This capability is crucial for tasks requiring specialized tools like document
conversion (libreoffice), media processing (ffmpeg), or image manipulation (imagemagick).

Installation command:
  subprocess.run('apt-get update && apt-get install -y package-name',
                 shell=True, capture_output=True)

Examples: libreoffice, ffmpeg, imagemagick, pandoc, texlive, ghostscript, etc.
Check availability: subprocess.run(['which', 'command'], ...)
List packages: subprocess.run(['dpkg', '-l'], ...)
Installation typically takes 10-60 seconds depending on package size.
</system_package_installation>

<file_input_output>
INPUT FILES:
Specify file_inputs with file_id and name from "Available files" section.
Files uploaded to /tmp/inputs/ before execution.
Example: file_inputs=[{"file_id": "file_abc...", "name": "document.pdf"}]
In code: open('/tmp/inputs/document.pdf', 'rb')

OUTPUT FILES:
Save to /tmp/ (any format: PDF, PNG, CSV, XLSX, TXT, etc.)
Bot automatically detects, downloads, uploads to Files API, sends to user,
and adds to context. Generated files become available for future operations.
Example: plt.savefig('/tmp/chart.png')
</file_input_output>

<verification_workflow>
CRITICAL - ALWAYS VERIFY OUTPUT:

After generating files, you MUST verify the result before considering task complete.
This verification is essential because it catches issues that code-level checks miss
(corrupted files, encoding problems, incomplete conversions, wrong output format).

Multi-step verification process:
1. Basic checks in code (file exists, reasonable size/format)
2. USE AVAILABLE VALIDATION TOOLS in next turn:
   - For PDFs: analyze_pdf tool verifies content is readable and correct
   - For images: analyze_image tool verifies image quality and content
3. If validation reveals problems, iterate with different approach:
   - Install specialized system tools via apt-get
   - Try alternative libraries or algorithms
   - Research better solutions
4. Verify again after each iteration until result is correct

Example workflow (PPTX to PDF conversion):
Turn 1: execute_python (attempts conversion, generates output.pdf)
Turn 2: analyze_pdf (validates PDF) ‚Üí finds problem: text unreadable, file only 8KB
Turn 3: execute_python (installs libreoffice, regenerates with soffice)
Turn 4: analyze_pdf (validates) ‚Üí confirms: content correct, proper size ‚úì

Note: You can call analyze_image and execute_python in PARALLEL if analyzing input
before processing (e.g., understand image content while preparing code).
</verification_workflow>

<workflow_examples>
Example 1 - Data analysis with chart:
User: "Analyze data.csv and create a chart"
1. Call: execute_python(file_inputs=[{"file_id":"file_xyz", "name":"data.csv"}])
2. Code: Read data, analyze, create plot, save to /tmp/chart.png
3. Bot downloads chart.png, sends to user, adds to context

Example 2 - Iterative approach with validation:
User: "Convert presentation.pptx to PDF"
1. Parallel: analyze_image(presentation) + execute_python(initial conversion attempt)
2. analyze_pdf ‚Üí detects quality issues
3. execute_python(installs libreoffice, uses soffice) ‚Üí better result
4. analyze_pdf ‚Üí confirms success
</workflow_examples>

<key_features>
- Secure isolated environment (ephemeral, starts fresh each time)
- Internet access (API calls, web scraping, downloads)
- Pip packages (numpy, pandas, matplotlib, requests, pillow, etc.)
- System packages (libreoffice, ffmpeg, imagemagick, pandoc, etc.)
- File processing (read/write/convert any format)
- Return: stdout, stderr, matplotlib plots, generated files
</key_features>

<when_to_use>
Use when user asks to: run code, perform calculations, analyze data, make HTTP requests,
process files, generate files (reports/charts/images), use Python libraries,
data transformations, file format conversions, image processing, or any Python-based task.
</when_to_use>

<when_not_to_use>
Do NOT use for: simple arithmetic (use built-in capabilities), tasks not requiring code
execution, or when user explicitly asks NOT to run code.
</when_not_to_use>

<limitations>
- 1 hour default timeout (3600 seconds, can be reduced for simple tasks)
- No persistence between calls (fresh sandbox each time)
- Limited CPU/RAM (1 vCPU, reasonable memory)
- Headless (no GUI/display output, but can save to files)
</limitations>

COST: ~$0.05/hour of runtime. Typical execution: <1 second = <$0.0001.
Free tier: $100 credit (~2000 hours).""",
    "input_schema": {
        "type": "object",
        "properties": {
            "code": {
                "type":
                    "string",
                "description": (
                    "Python code to execute. Can include imports, multiple "
                    "lines, functions, classes, etc. Input files at /tmp/inputs/, "
                    "save outputs to /tmp/. Use print() for debug output.")
            },
            "file_inputs": {
                "type":
                    "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "file_id": {
                            "type":
                                "string",
                            "description": (
                                "claude_file_id from 'Available files' section "
                                "in system prompt (e.g., 'file_abc123...').")
                        },
                        "name": {
                            "type":
                                "string",
                            "description": (
                                "Original filename from 'Available files' "
                                "(e.g., 'document.pdf'). File will be available "
                                "at /tmp/inputs/{name} in sandbox.")
                        }
                    },
                    "required": ["file_id", "name"]
                },
                "description":
                    ("List of input files to upload to sandbox. "
                     "Use file_id and name from 'Available files' section. "
                     "Files uploaded to /tmp/inputs/ before code execution. "
                     "Optional - omit if no file inputs needed.")
            },
            "requirements": {
                "type":
                    "string",
                "description": (
                    "Space-separated list of pip packages to install before "
                    "execution (e.g., 'numpy pandas matplotlib requests pillow'). "
                    "Only packages not in Python standard library. Optional.")
            },
            "timeout": {
                "type":
                    "number",
                "description": (
                    "Maximum execution time in seconds. Default: 3600 (1 hour). "
                    "Can be reduced for faster feedback on simple tasks. Optional."
                )
            }
        },
        "required": ["code"]
    },
    # Phase 1.5 Stage 6: Enable prompt caching for all tool definitions
    # This MUST be on the LAST tool in TOOL_DEFINITIONS list
    # Caches all 5 tools (~3,268 tokens) with 1-hour ephemeral cache
    # Cost: 10x reduction on cache hits ($0.15 ‚Üí $0.015 per 1M tokens)
    # Shared across ALL users (same tool definitions for everyone)
    # 1-hour TTL: 2x write cost but lasts 12x longer ‚Üí ~41% savings vs 5-min
    "cache_control": {
        "type": "ephemeral",
        "ttl": "1h"  # 1-hour cache for better cost efficiency
    }
}


def format_execute_python_result(
    tool_input: Dict[str, Any],
    result: Dict[str, Any],
) -> str:
    """Format execute_python result for user display.

    Args:
        tool_input: The input parameters (code, file_inputs, etc.).
        result: The result dictionary with stdout, stderr, success, error.

    Returns:
        Formatted system message string.
    """
    if result.get("success") == "true":
        stdout = result.get("stdout", "").strip()
        if stdout:
            # Truncate long output
            preview = stdout[:100] + "..." if len(stdout) > 100 else stdout
            return f"\n[‚úÖ –ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω: {preview}]\n"
        return "\n[‚úÖ –ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ]\n"
    else:
        error = result.get("error", "unknown error")
        # Truncate long error
        preview = error[:80] + "..." if len(error) > 80 else error
        return f"\n[‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {preview}]\n"


# Unified tool configuration
# Import here to avoid circular dependencies at module level
from core.tools.base import ToolConfig  # pylint: disable=wrong-import-position

TOOL_CONFIG = ToolConfig(
    name="execute_python",
    definition=EXECUTE_PYTHON_TOOL,
    executor=execute_python,
    emoji="üêç",
    needs_bot_session=True,
    format_result=format_execute_python_result,
)
