"""OpenAI assistant tools wrappers and chat completions."""

import aiogram
import openai

from src.utils import bot_globals, output_formatting
from src.openai import openai_globals


class StreamEventHandler(openai.AsyncAssistantEventHandler):
    """Class for handling streamed events generated by assistants"""

    def __init__(self, message) -> None:
        """Initialize variables needed to format tg message while streaming."""
        super().__init__()
        self.message = message
        self.response = ""
        self.delta_chars_num = 0
        self.chars_to_update = 0

    async def on_text_created(self, text) -> None:
        """Send a text placeholder to a user until a response will be generated."""
        self.message = await self.message.answer("...")

    async def on_text_delta(self, delta, snapshot):
        """Edit message each time when enough difference is accumulated."""
        self.response += delta.value
        self.delta_chars_num += len(delta.value)
        if self.delta_chars_num > self.chars_to_update:
            self.delta_chars_num = 0
            self.chars_to_update = output_formatting.stream_increment(
                len(self.response)
            )
            self.message = await self.message.edit_text(self.response + "...")

    async def on_text_done(self, text):
        """After generation remove decorative '...' at the end of the message."""
        await self.message.edit_text(text.value)

    async def on_tool_call_created(self, tool_call):
        print(f"\nassistant > {tool_call.type}\n", flush=True)

    async def on_tool_call_delta(self, delta, snapshot):
        if delta.type == "code_interpreter":
            if delta.code_interpreter.input:
                print(delta.code_interpreter.input, end="", flush=True)
            if delta.code_interpreter.outputs:
                print("\n\noutput >", flush=True)
                for output in delta.code_interpreter.outputs:
                    if output.type == "logs":
                        print(f"\n{output.logs}", flush=True)


async def stream_events(message: aiogram.types.Message, user: dict) -> None:
    """Wrapper over OpenAI's async streaming completion API call."""
    await bot_globals.bot.send_chat_action(
        message.chat.id, aiogram.enums.ChatAction.TYPING
    )
    async with openai_globals.client.beta.threads.runs.stream(
        thread_id=user["thread_id"],
        assistant_id=user["assistant_id"],
        event_handler=StreamEventHandler(message),
    ) as stream:
        await stream.until_done()
