# Architecture Improvement Plan

**Date:** 2026-01-27
**Status:** Phase 1-3.3 Complete, Phase 3.4 In Progress (modules ready), Phase 4 Pending
**Based on:** Comprehensive Architecture Audit

---

## Executive Summary

Audit –≤—ã—è–≤–∏–ª 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–æ–±–ª–µ–º:
1. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî race conditions, –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ TTL, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ retry
2. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** ‚Äî —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤, –Ω–µ–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
3. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** ‚Äî –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞, –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–µ —Ö–µ–Ω–¥–ª–µ—Ä—ã

---

## Phase 1: Critical Fixes (P0) ‚Äî ‚úÖ COMPLETE

### 1.1 TTL Mismatch Fix ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç `messages TTL=300s`, `threads TTL=600s`, –Ω–æ –∫–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `3600s`.

**–§–∞–π–ª—ã:**
- `bot/cache/keys.py:95-98`
- `docs/phase-3.2-redis-cache.md:92`

**–†–µ—à–µ–Ω–∏–µ:** –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ–¥ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (3600s —Ä–∞–∑—É–º–Ω–µ–µ –¥–ª—è production).

```python
# keys.py - —Ç–µ–∫—É—â–µ–µ (–æ—Å—Ç–∞–≤–∏—Ç—å)
THREAD_TTL = 3600  # 1 hour
MESSAGES_TTL = 3600  # 1 hour

# docs/phase-3.2-redis-cache.md - –æ–±–Ω–æ–≤–∏—Ç—å
# Thread cache TTL: 3600 seconds (1 hour)
# Messages cache TTL: 3600 seconds (1 hour)
```

**Effort:** 30 –º–∏–Ω—É—Ç

---

### 1.2 Atomic Message Cache Updates ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** Race condition –≤ `thread_cache.py:359-423`:
```python
data = await redis.get(key)           # Read
cached["messages"].append(new_msg)    # Modify
await redis.setex(key, TTL, ...)      # Write
# –ú–µ–∂–¥—É Read –∏ Write –¥—Ä—É–≥–æ–π –ø—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –∑–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ!
```

**–†–µ—à–µ–Ω–∏–µ:** Lua —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ append:

**–§–∞–π–ª:** `bot/cache/thread_cache.py`

```python
# Lua script for atomic message append
APPEND_MESSAGE_SCRIPT = """
local key = KEYS[1]
local new_message = ARGV[1]
local ttl = tonumber(ARGV[2])

local data = redis.call('GET', key)
if not data then
    return 0  -- Cache miss, let caller handle
end

local cached = cjson.decode(data)
local messages = cached.messages or {}
table.insert(messages, cjson.decode(new_message))
cached.messages = messages
cached.cached_at = ARGV[3]

redis.call('SETEX', key, ttl, cjson.encode(cached))
return 1  -- Success
"""

async def append_message_atomic(
    thread_id: int,
    message: dict,
) -> bool:
    """Atomically append message to cache.

    Returns:
        True if appended, False if cache miss (caller should rebuild).
    """
    redis = await get_redis()
    key = messages_key(thread_id)

    result = await redis.eval(
        APPEND_MESSAGE_SCRIPT,
        1,  # number of keys
        key,
        json.dumps(message),
        str(MESSAGES_TTL),
        datetime.utcnow().isoformat(),
    )

    return result == 1
```

**Effort:** 2-3 —á–∞—Å–∞

---

### 1.3 Write-Behind Retry Logic ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** `write_behind.py` —Ç–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ flush:
```python
try:
    await self._flush_batch(items)
except Exception as e:
    logger.error(...)
    # items LOST!
```

**–†–µ—à–µ–Ω–∏–µ:** –í–æ–∑–≤—Ä–∞—â–∞—Ç—å failed items –≤ –æ—á–µ—Ä–µ–¥—å —Å exponential backoff:

**–§–∞–π–ª:** `bot/cache/write_behind.py`

```python
MAX_RETRY_ATTEMPTS = 3
RETRY_BACKOFF_BASE = 2  # seconds

async def _flush_batch(self, items: list[WriteItem]) -> None:
    """Flush batch with retry logic."""
    failed_items = []

    for item in items:
        try:
            await self._write_single(item)
        except Exception as e:
            item.retry_count = getattr(item, 'retry_count', 0) + 1

            if item.retry_count < MAX_RETRY_ATTEMPTS:
                failed_items.append(item)
                logger.warning(
                    "write_behind.item_failed_will_retry",
                    write_type=item.write_type,
                    retry_count=item.retry_count,
                    error=str(e),
                )
            else:
                logger.error(
                    "write_behind.item_failed_max_retries",
                    write_type=item.write_type,
                    data=item.data,
                    error=str(e),
                )

    # Return failed items to queue for retry
    if failed_items:
        for item in failed_items:
            # Add delay based on retry count
            item.retry_after = time.time() + (RETRY_BACKOFF_BASE ** item.retry_count)
            await self._queue.put(item)
```

**Effort:** 2-3 —á–∞—Å–∞

---

## Phase 2: Documentation Updates (P1) ‚Äî ‚úÖ COMPLETE

### 2.1 Update CLAUDE.md File Structure ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `telegram/pipeline/` ‚Äî –∫–ª—é—á–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞.

**–î–æ–±–∞–≤–∏—Ç—å –≤ —Å–µ–∫—Ü–∏—é File Structure:**

```markdown
‚îÇ   ‚îú‚îÄ‚îÄ telegram/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/           # Message handlers (claude.py is main)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline/           # Unified message processing (NEW)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handler.py      # Entry point, batching
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processor.py    # Core processing logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py   # Message normalization
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py       # ProcessedMessage, UploadedFile
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queue.py        # Message queue management
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tracker.py      # Upload tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middlewares/        # Logging, database, balance check
```

**Effort:** 30 –º–∏–Ω—É—Ç

---

### 2.2 Update phase-1.2-database.md ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç 5 –º–æ–¥–µ–ª–µ–π –∏ 5 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤.

**–î–æ–±–∞–≤–∏—Ç—å:**

```markdown
## Models (9 total)

| Model | File | Purpose |
|-------|------|---------|
| User | user.py | Telegram users, balance, settings |
| Chat | chat.py | Chats/groups/channels |
| Thread | thread.py | Conversation threads |
| Message | message.py | Messages with JSONB attachments |
| **UserFile** | user_file.py | Files API integration |
| **Payment** | payment.py | Telegram Stars payments |
| **BalanceOperation** | balance_operation.py | Balance audit trail |
| **ToolCall** | tool_call.py | Tool execution history |

## Repositories (9 total)

| Repository | Purpose |
|------------|---------|
| UserRepository | User CRUD, balance ops |
| ChatRepository | Chat CRUD |
| ThreadRepository | Thread CRUD with caching |
| MessageRepository | Message CRUD, history |
| **UserFileRepository** | File management |
| **PaymentRepository** | Payment records |
| **BalanceOperationRepository** | Balance audit |
| **ToolCallRepository** | Tool call tracking |
```

**Effort:** 1 —á–∞—Å

---

### 2.3 Update CLAUDE.md Tools Table ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ–∫–∞–∑–∞–Ω–æ 9 –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Ä–µ–∞–ª—å–Ω–æ 10.

**–û–±–Ω–æ–≤–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É:**

```markdown
### Tools (11 total)
| Tool | Purpose | Cost |
|------|---------|------|
| analyze_image | Vision analysis via Files API | Paid |
| analyze_pdf | PDF text + visual analysis | Paid |
| execute_python | E2B sandbox with file I/O | Paid |
| generate_image | Google Gemini image generation | Paid |
| transcribe_audio | Whisper speech-to-text | Paid |
| web_search | Internet search (server-side) | Paid |
| web_fetch | Fetch URL content (server-side) | Free |
| render_latex | LaTeX to PNG | Free |
| deliver_file | Send cached file to user | Free |
| preview_file | Verify file before delivery | Free* |
| **cost_estimator** | Estimate tool costs | Free |

*preview_file is FREE for text/CSV, PAID for images/PDFs (Vision API)
```

**Effort:** 30 –º–∏–Ω—É—Ç

---

### 2.4 Update phase-1.5-agent-tools.md ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** execute_python –ø–æ–∫–∞–∑–∞–Ω –∫–∞–∫ "TODO/pending", –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω.

**–û–±–Ω–æ–≤–∏—Ç—å Stage 5:**

```markdown
## Stage 5: Code Execution (execute_python) ‚Äî IMPLEMENTED

**Status:** ‚úÖ Complete (E2B integration)

**Features:**
- E2B Code Interpreter sandbox
- Pip package installation
- File I/O (upload inputs, download outputs)
- Timeout handling (default 1 hour)
- Sandbox reuse between calls (cached in Redis)
- Output file caching with preview generation

**Implementation:** `bot/core/tools/execute_python.py` (800+ lines)
```

**Effort:** 30 –º–∏–Ω—É—Ç

---

## Phase 3: Architecture Refactoring (P2)

### 3.1 Create ServiceFactory ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ 5+ –º–µ—Å—Ç–∞—Ö:
```python
# –ü–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –≤–µ–∑–¥–µ
user_repo = UserRepository(session)
balance_op_repo = BalanceOperationRepository(session)
balance_service = BalanceService(session, user_repo, balance_op_repo)
```

**–†–µ—à–µ–Ω–∏–µ:** –°–æ–∑–¥–∞—Ç—å `ServiceFactory`:

**–§–∞–π–ª:** `bot/services/factory.py` (NEW)

```python
"""Service factory for dependency injection.

Eliminates duplicate service initialization across handlers.
Use: services = ServiceFactory(session)
     await services.balance.charge_user(...)

NO __init__.py - use direct import:
    from services.factory import ServiceFactory
"""

from dataclasses import dataclass
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from sqlalchemy.ext.asyncio import AsyncSession

from db.repositories.user_repository import UserRepository
from db.repositories.balance_operation_repository import BalanceOperationRepository
from db.repositories.user_file_repository import UserFileRepository
from db.repositories.message_repository import MessageRepository
from db.repositories.thread_repository import ThreadRepository
from services.balance_service import BalanceService


@dataclass
class ServiceFactory:
    """Factory for creating service instances with shared session.

    Usage:
        async with get_session() as session:
            services = ServiceFactory(session)
            await services.balance.charge_user(user_id, amount, ...)
            await services.messages.create_message(...)

    Benefits:
        - Single point of service creation
        - Repositories created once per request
        - Easy to mock in tests
        - Consistent initialization
    """

    session: "AsyncSession"

    # Lazy-loaded repositories
    _user_repo: UserRepository | None = None
    _balance_op_repo: BalanceOperationRepository | None = None
    _user_file_repo: UserFileRepository | None = None
    _message_repo: MessageRepository | None = None
    _thread_repo: ThreadRepository | None = None

    # Lazy-loaded services
    _balance_service: BalanceService | None = None

    @property
    def users(self) -> UserRepository:
        if self._user_repo is None:
            self._user_repo = UserRepository(self.session)
        return self._user_repo

    @property
    def balance_ops(self) -> BalanceOperationRepository:
        if self._balance_op_repo is None:
            self._balance_op_repo = BalanceOperationRepository(self.session)
        return self._balance_op_repo

    @property
    def files(self) -> UserFileRepository:
        if self._user_file_repo is None:
            self._user_file_repo = UserFileRepository(self.session)
        return self._user_file_repo

    @property
    def messages(self) -> MessageRepository:
        if self._message_repo is None:
            self._message_repo = MessageRepository(self.session)
        return self._message_repo

    @property
    def threads(self) -> ThreadRepository:
        if self._thread_repo is None:
            self._thread_repo = ThreadRepository(self.session)
        return self._thread_repo

    @property
    def balance(self) -> BalanceService:
        if self._balance_service is None:
            self._balance_service = BalanceService(
                self.session,
                self.users,
                self.balance_ops,
            )
        return self._balance_service
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–∑–∞–º–µ–Ω–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–¥–∞):**

```python
# –ë–´–õ–û (–≤ 5+ –º–µ—Å—Ç–∞—Ö):
user_repo = UserRepository(session)
balance_op_repo = BalanceOperationRepository(session)
balance_service = BalanceService(session, user_repo, balance_op_repo)
await balance_service.charge_user(user_id, amount, description)

# –°–¢–ê–õ–û:
from services.factory import ServiceFactory
services = ServiceFactory(session)
await services.balance.charge_user(user_id, amount, description)
```

**–§–∞–π–ª—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:**
- `telegram/handlers/claude.py`
- `telegram/handlers/claude_tools.py`
- `services/topic_naming.py`
- `telegram/middlewares/balance_middleware.py`
- `telegram/pipeline/processor.py`

**Effort:** 4-6 —á–∞—Å–æ–≤

---

### 3.2 –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è Singleton Pattern ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** 3 —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Å–∏–Ω–≥–ª—Ç–æ–Ω–æ–≤ –≤ –∫–æ–¥–µ.

**–¢–µ–∫—É—â–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:**
```python
# Pattern 1: Global + init function (claude.py)
claude_provider = None
def init_claude_provider(api_key): ...

# Pattern 2: Global + getter (topic_naming.py)
_service = None
def get_service():
    global _service
    if _service is None:
        _service = Service()
    return _service

# Pattern 3: Double-check (clients.py)
_client = None
def get_client():
    global _client
    if _client is None:
        _client = Client()
    return _client
```

**–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–¥–∏–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω ‚Äî Pattern 2 (lazy getter) –≤–µ–∑–¥–µ:

**–§–∞–π–ª:** `bot/core/singleton.py` (NEW)

```python
"""Singleton pattern utilities.

Provides consistent lazy initialization for service singletons.
Thread-safe through Python's GIL for simple cases.

Usage:
    from core.singleton import singleton

    @singleton
    def get_my_service() -> MyService:
        return MyService(config.SETTING)
"""

from functools import wraps
from typing import TypeVar, Callable

T = TypeVar('T')


def singleton(func: Callable[[], T]) -> Callable[[], T]:
    """Decorator for singleton getter functions.

    Caches the result of the first call and returns it
    for all subsequent calls.

    Example:
        @singleton
        def get_claude_provider() -> ClaudeProvider:
            return ClaudeProvider(config.ANTHROPIC_API_KEY)

        # First call creates instance
        provider = get_claude_provider()

        # Subsequent calls return same instance
        same_provider = get_claude_provider()
        assert provider is same_provider
    """
    instance = None

    @wraps(func)
    def wrapper() -> T:
        nonlocal instance
        if instance is None:
            instance = func()
        return instance

    # Allow resetting for tests
    def reset():
        nonlocal instance
        instance = None

    wrapper.reset = reset
    return wrapper
```

**–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–∏–Ω–≥–ª—Ç–æ–Ω–æ–≤:**

```python
# core/clients.py
from core.singleton import singleton

@singleton
def get_anthropic_async_client() -> AsyncAnthropic:
    return AsyncAnthropic(api_key=config.ANTHROPIC_API_KEY)

@singleton
def get_anthropic_files_client() -> AsyncAnthropic:
    return AsyncAnthropic(
        api_key=config.ANTHROPIC_API_KEY,
        default_headers={"anthropic-beta": "files-api-2025-04-14"},
    )

# services/topic_naming.py
from core.singleton import singleton

@singleton
def get_topic_naming_service() -> TopicNamingService:
    return TopicNamingService()

# telegram/handlers/claude.py
from core.singleton import singleton

@singleton
def get_claude_provider() -> ClaudeProvider:
    return ClaudeProvider(config.ANTHROPIC_API_KEY)
```

**Effort:** 3-4 —á–∞—Å–∞

---

### 3.3 Extract BalancePolicy ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –õ–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–ª–∞–Ω—Å–∞ –≤ 4 –º–µ—Å—Ç–∞—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏.

**–†–µ—à–µ–Ω–∏–µ:** –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `BalancePolicy`:

**–§–∞–π–ª:** `bot/services/balance_policy.py` (NEW)

```python
"""Unified balance checking policy.

Single source of truth for:
- Can user make request? (before handler)
- Can user use paid tool? (during handler)
- Charge user for usage (after response)

NO __init__.py - use direct import:
    from services.balance_policy import BalancePolicy
"""

from decimal import Decimal
from typing import Optional
from dataclasses import dataclass

from cache.user_cache import get_cached_user
from db.repositories.user_repository import UserRepository


@dataclass
class BalanceCheckResult:
    """Result of balance check."""
    allowed: bool
    balance: Decimal
    source: str  # "cache" or "database"
    reason: Optional[str] = None


class BalancePolicy:
    """Unified balance checking policy.

    Implements soft-check: user can go negative ONCE, then blocked.
    This allows completing started requests without abrupt cutoff.

    Usage:
        policy = BalancePolicy()

        # Quick check (cache-first)
        result = await policy.can_make_request(user_id)
        if not result.allowed:
            return "Insufficient balance"

        # Tool pre-check
        can_use = await policy.can_use_paid_tool(user_id, tool_name)
    """

    # Minimum balance to start new request
    MIN_BALANCE_FOR_REQUEST = Decimal("0")

    # Minimum balance to use paid tools
    MIN_BALANCE_FOR_TOOLS = Decimal("0")

    async def can_make_request(
        self,
        user_id: int,
        session: Optional["AsyncSession"] = None,
    ) -> BalanceCheckResult:
        """Check if user can make a new request.

        Uses cache-first approach for speed.
        Falls back to database if cache miss.

        Args:
            user_id: Telegram user ID.
            session: Optional DB session for fallback.

        Returns:
            BalanceCheckResult with allowed status and balance.
        """
        # Try cache first
        cached_user = await get_cached_user(user_id)

        if cached_user is not None:
            balance = cached_user.balance
            allowed = balance > self.MIN_BALANCE_FOR_REQUEST
            return BalanceCheckResult(
                allowed=allowed,
                balance=balance,
                source="cache",
                reason=None if allowed else "Insufficient balance (cached)",
            )

        # Cache miss - check database
        if session is None:
            # No session, allow request (will check later)
            return BalanceCheckResult(
                allowed=True,
                balance=Decimal("0"),
                source="unknown",
                reason="Cache miss, no session",
            )

        user_repo = UserRepository(session)
        user = await user_repo.get_by_id(user_id)

        if user is None:
            # New user, allow first request
            return BalanceCheckResult(
                allowed=True,
                balance=Decimal("0"),
                source="database",
                reason="New user",
            )

        balance = user.balance
        allowed = balance > self.MIN_BALANCE_FOR_REQUEST
        return BalanceCheckResult(
            allowed=allowed,
            balance=balance,
            source="database",
            reason=None if allowed else "Insufficient balance",
        )

    async def can_use_paid_tool(
        self,
        user_id: int,
        tool_name: str,
    ) -> bool:
        """Check if user can use a paid tool.

        More lenient than can_make_request - allows tools
        if user has any positive balance (soft-check).

        Args:
            user_id: Telegram user ID.
            tool_name: Name of the tool (for logging).

        Returns:
            True if user can use the tool.
        """
        cached_user = await get_cached_user(user_id)

        if cached_user is None:
            # Cache miss - allow (will charge later)
            return True

        return cached_user.balance > self.MIN_BALANCE_FOR_TOOLS


# Global instance
_balance_policy: Optional[BalancePolicy] = None


def get_balance_policy() -> BalancePolicy:
    """Get singleton BalancePolicy instance."""
    global _balance_policy
    if _balance_policy is None:
        _balance_policy = BalancePolicy()
    return _balance_policy
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
# –í BalanceMiddleware:
from services.balance_policy import get_balance_policy

policy = get_balance_policy()
result = await policy.can_make_request(user_id, session)
if not result.allowed:
    await message.answer(f"Insufficient balance: ${result.balance}")
    return None

# –í claude_tools.py:
policy = get_balance_policy()
if not await policy.can_use_paid_tool(user_id, tool_name):
    return {"error": "Insufficient balance for paid tool"}
```

**Effort:** 4-5 —á–∞—Å–æ–≤

---

### 3.4 Split Streaming Handler üîÑ

**–ü—Ä–æ–±–ª–µ–º–∞:** `_stream_with_unified_events` ‚Äî 572 —Å—Ç—Ä–æ–∫–∏, 7 return values.

**–°—Ç–∞—Ç—É—Å:** –í –ø—Ä–æ—Ü–µ—Å—Å–µ. –°–æ–∑–¥–∞–Ω—ã –º–æ–¥—É–ª–∏, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ claude.py –æ–∂–∏–¥–∞–µ—Ç—Å—è.

**–†–µ—à–µ–Ω–∏–µ:** –†–∞–∑–±–∏—Ç—å –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

**–§–∞–π–ª:** `bot/telegram/handlers/streaming/` (NEW directory)

```
streaming/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ orchestrator.py    # Main coordination
‚îú‚îÄ‚îÄ session.py         # StreamingSession state
‚îú‚îÄ‚îÄ tool_executor.py   # Tool execution loop
‚îú‚îÄ‚îÄ file_processor.py  # Generated file handling
‚îú‚îÄ‚îÄ cost_tracker.py    # Partial billing
‚îî‚îÄ‚îÄ models.py          # StreamResult, CancellationReason
```

**–ö–ª—é—á–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã:**

```python
# streaming/models.py
@dataclass
class StreamResult:
    """Result of streaming operation."""
    text: str
    message: types.Message
    needs_continuation: bool
    was_cancelled: bool
    cancellation_reason: Optional[CancellationReason]
    thinking_tokens: int
    output_tokens: int
    cost_usd: Decimal

    def build_continuation_request(self) -> "StreamRequest":
        """Build request for continuation if needed."""
        ...


# streaming/orchestrator.py
class StreamingOrchestrator:
    """Coordinates streaming, tools, files, and billing.

    Replaces monolithic _stream_with_unified_events function.
    Each responsibility delegated to specialized component.
    """

    def __init__(
        self,
        tool_executor: ToolExecutor,
        file_processor: FileProcessor,
        cost_tracker: CostTracker,
    ):
        self.tool_executor = tool_executor
        self.file_processor = file_processor
        self.cost_tracker = cost_tracker

    async def stream_with_continuation(
        self,
        request: StreamRequest,
    ) -> StreamResult:
        """Stream response with automatic continuation.

        Handles the full loop:
        1. Stream from Claude API
        2. Execute tools if requested
        3. Process generated files
        4. Track costs
        5. Continue if needed (tool results, length limit)
        """
        while True:
            result = await self._stream_single(request)

            if not result.needs_continuation:
                return result

            # Build continuation request
            request = result.build_continuation_request()

    async def _stream_single(
        self,
        request: StreamRequest,
    ) -> StreamResult:
        """Single streaming iteration (may need continuation)."""
        session = StreamingSession(request)

        async for event in self._stream_events(request):
            await session.process_event(event)

            # Check for cancellation
            if await self._check_cancellation(session):
                return session.build_cancelled_result()

            # Process tool calls
            if event.type == "tool_use":
                tool_result = await self.tool_executor.execute(
                    event.tool_call,
                    session,
                )
                session.add_tool_result(tool_result)

                # Process any generated files
                if tool_result.output_files:
                    await self.file_processor.process(
                        tool_result.output_files,
                        session,
                    )

        # Track final cost
        await self.cost_tracker.record(session)

        return session.build_result()
```

**Effort:** 8-12 —á–∞—Å–æ–≤ (–±–æ–ª—å—à–æ–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥)

---

## Phase 4: Additional Improvements (P3)

### 4.1 Cache Warming Strategy

**–ü—Ä–æ–±–ª–µ–º–∞:** Cache miss –Ω–∞ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –≤ —Å–µ—Å—Å–∏–∏.

**–†–µ—à–µ–Ω–∏–µ:** Warm cache –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ thread:

```python
# thread_resolver.py
async def get_or_create_thread(...):
    thread, was_created = await thread_repo.get_or_create_thread(...)

    if was_created:
        # Pre-populate caches for better first-message performance
        await cache_thread(thread)
        await cache_messages(thread.id, [])  # Empty history
        await cache_files(thread.id, [])     # No files yet
```

**Effort:** 2 —á–∞—Å–∞

---

### 4.2 Redis Pipeline for Batch Operations

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö Redis calls.

**–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pipeline –¥–ª—è batch –æ–ø–µ—Ä–∞—Ü–∏–π:

```python
async def get_user_context(user_id: int, thread_id: int) -> UserContext:
    """Get all user context in single Redis roundtrip."""
    redis = await get_redis()

    async with redis.pipeline() as pipe:
        pipe.get(user_key(user_id))
        pipe.get(thread_key(thread_id))
        pipe.get(messages_key(thread_id))
        pipe.get(files_key(thread_id))

        results = await pipe.execute()

    return UserContext(
        user=parse_user(results[0]),
        thread=parse_thread(results[1]),
        messages=parse_messages(results[2]),
        files=parse_files(results[3]),
    )
```

**Effort:** 4-6 —á–∞—Å–æ–≤

---

### 4.3 Standardize Error Handling

**–ü—Ä–æ–±–ª–µ–º–∞:** 6+ —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫.

**–†–µ—à–µ–Ω–∏–µ:** –°–æ–∑–¥–∞—Ç—å error classification system:

```python
# core/errors.py

class BotError(Exception):
    """Base class for bot errors."""
    recoverable: bool = True
    user_message: str = "An error occurred"
    log_level: str = "warning"


class InsufficientBalanceError(BotError):
    """User has insufficient balance."""
    recoverable = True
    user_message = "Insufficient balance. Please top up with /pay"
    log_level = "info"  # Expected behavior, not warning


class ToolExecutionError(BotError):
    """Tool failed to execute."""
    recoverable = True
    user_message = "Tool execution failed. Please try again."
    log_level = "warning"


class APIError(BotError):
    """External API error."""
    recoverable = False
    user_message = "Service temporarily unavailable"
    log_level = "error"
```

**Effort:** 4-6 —á–∞—Å–æ–≤

---

## Implementation Timeline

| Phase | Items | Effort | Priority |
|-------|-------|--------|----------|
| **Phase 1** | TTL fix, Atomic updates, Retry logic | 5-7 —á–∞—Å–æ–≤ | P0 (—Å—Ä–æ—á–Ω–æ) |
| **Phase 2** | Documentation updates | 3-4 —á–∞—Å–∞ | P1 (—ç—Ç–∞ –Ω–µ–¥–µ–ª—è) |
| **Phase 3.1** | ServiceFactory | 4-6 —á–∞—Å–æ–≤ | P2 |
| **Phase 3.2** | Singleton pattern | 3-4 —á–∞—Å–∞ | P2 |
| **Phase 3.3** | BalancePolicy | 4-5 —á–∞—Å–æ–≤ | P2 |
| **Phase 3.4** | Split streaming handler | 8-12 —á–∞—Å–æ–≤ | P2 (–±–æ–ª—å—à–æ–π) |
| **Phase 4** | Cache warming, Pipeline, Errors | 10-14 —á–∞—Å–æ–≤ | P3 (future) |

**Total estimated effort:** 37-52 —á–∞—Å–∞

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Lua script compatibility | Redis version issues | Test on staging first |
| ServiceFactory breaks DI | Harder testing | Keep original constructors |
| Streaming split regression | User-facing bugs | Comprehensive test coverage |
| Cache warming overhead | Slower thread creation | Make async, measure impact |

---

## Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Message cache race conditions | Unknown | 0 |
| Write-behind data loss | ~1-2% | <0.1% |
| Service initialization LOC | 15 lines/place | 2 lines/place |
| Streaming handler size | 572 lines | <200 lines/file |
| Documentation coverage | ~70% | 95% |

---

## Next Steps

1. **Approve plan** ‚Äî review priorities with team
2. **Phase 1** ‚Äî critical fixes first (TTL, atomic, retry)
3. **Phase 2** ‚Äî documentation updates (parallel with Phase 1)
4. **Phase 3** ‚Äî architecture improvements (incremental)
5. **Phase 4** ‚Äî optimization (after stabilization)

---

*Plan created: 2026-01-27*
*Based on: Comprehensive Architecture Audit*
